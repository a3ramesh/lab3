{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bHQx6TDJ7gY4"
      },
      "source": [
        "# Homework 2\n",
        "In this assignment, we will be building a Naïve Bayes classifier and a SVM model for the productivity satisfaction of [the given dataset](https://archive.ics.uci.edu/ml/datasets/Productivity+Prediction+of+Garment+Employees), the productivity of garment employees.\n",
        "\n",
        "## Background\n",
        "The Garment Industry is one of the key examples of the industrial globalization of this modern era. It is a highly labour-intensive industry with lots of manual processes. Satisfying the huge global demand for garment products is mostly dependent on the production and delivery performance of the employees in the garment manufacturing companies. So, it is highly desirable among the decision makers in the garments industry to track, analyse and predict the productivity performance of the working teams in their factories.\n",
        "\n",
        "## Dataset Attribute Information\n",
        "\n",
        "1. **date**: Date in MM-DD-YYYY\n",
        "2. **day**: Day of the Week\n",
        "3. **quarter** : A portion of the month. A month was divided into four quarters\n",
        "4. **department** : Associated department with the instance\n",
        "5. **team_no** : Associated team number with the instance\n",
        "6. **no_of_workers** : Number of workers in each team\n",
        "7. **no_of_style_change** : Number of changes in the style of a particular product\n",
        "8. **targeted_productivity** : Targeted productivity set by the Authority for each team for each day.\n",
        "9. **smv** : Standard Minute Value, it is the allocated time for a task\n",
        "10. **wip** : Work in progress. Includes the number of unfinished items for products\n",
        "11. **over_time** : Represents the amount of overtime by each team in minutes\n",
        "12. **incentive** : Represents the amount of financial incentive (in BDT) that enables or motivates a particular course of action.\n",
        "13. **idle_time** : The amount of time when the production was interrupted due to several reasons\n",
        "14. **idle_men** : The number of workers who were idle due to production interruption\n",
        "15. **actual_productivity** : The actual % of productivity that was delivered by the workers. It ranges from 0-1.\n",
        "\n",
        "### Libraries that can be used: numpy, scipy, pandas, scikit-learn, cvxpy, imbalanced-learn\n",
        "Any libraries used in the discussion materials are also allowed.\n",
        "\n",
        "#### Other Notes\n",
        "\n",
        " - Don't worry about not being able to achieve high accuracy, it is neither the goal nor the grading standard of this assignment. <br >\n",
        " - If not specified, you are not required to do hyperparameter tuning, but feel free to do so if you'd like.\n",
        "\n",
        "#### Trouble Shooting\n",
        "In case you have trouble installing and using imbalanced-learn(imblearn) <br >\n",
        "Run the below code cell, then go to the selection bar at top: Kernel > Restart. <br >\n",
        "Then try `import imblearn` to see if things work."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "v-KORp1-961U",
        "outputId": "ce32a49f-6400-4f58-9015-57213701fa82"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "'Linux'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {}
        }
      ],
      "source": [
        "import platform\n",
        "display(platform.system())\n",
        "import os\n",
        "file_download_link = 'https://www.dropbox.com/scl/fi/j1dxtqjerbdbl81e05nvp/hw4data.zip?rlkey=8mkxz4j8lngziok6on782a8u4&dl=0'\n",
        "if os.name == 'nt':\n",
        "    print('Please download your dataset here:', file_download_link)\n",
        "else:\n",
        "    # We need to first download the data here:\n",
        "    !wget -O data.zip \"$file_download_link\" -o /dev/null\n",
        "    !unzip data.zip > /dev/null"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "zAn5IT0BKu28"
      },
      "outputs": [],
      "source": [
        "!sed 's/,/\\t/g' garments_worker_productivity.csv > garments_worker_productivity.tsv"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JRujZpIb-cTG"
      },
      "outputs": [],
      "source": [
        "# If your data is on google drive then uncomment the code below to access\n",
        "# your google drive.\n",
        "#from google.colab import drive\n",
        "#drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "uXvnD44V7gY7",
        "outputId": "745c5e04-c98d-489c-d23b-e13dff01549c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: imbalanced-learn in /usr/local/lib/python3.10/dist-packages (0.12.4)\n",
            "Collecting delayed\n",
            "  Downloading delayed-1.2.0b2-py2.py3-none-any.whl.metadata (9.5 kB)\n",
            "Requirement already satisfied: numpy>=1.17.3 in /usr/local/lib/python3.10/dist-packages (from imbalanced-learn) (1.26.4)\n",
            "Requirement already satisfied: scipy>=1.5.0 in /usr/local/lib/python3.10/dist-packages (from imbalanced-learn) (1.13.1)\n",
            "Requirement already satisfied: scikit-learn>=1.0.2 in /usr/local/lib/python3.10/dist-packages (from imbalanced-learn) (1.5.2)\n",
            "Requirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from imbalanced-learn) (1.4.2)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from imbalanced-learn) (3.5.0)\n",
            "Collecting hiredis (from delayed)\n",
            "  Downloading hiredis-3.0.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (7.2 kB)\n",
            "Collecting redis (from delayed)\n",
            "  Downloading redis-5.2.0-py3-none-any.whl.metadata (9.1 kB)\n",
            "Requirement already satisfied: msgpack in /usr/local/lib/python3.10/dist-packages (from delayed) (1.1.0)\n",
            "Requirement already satisfied: async-timeout>=4.0.3 in /usr/local/lib/python3.10/dist-packages (from redis->delayed) (4.0.3)\n",
            "Downloading delayed-1.2.0b2-py2.py3-none-any.whl (12 kB)\n",
            "Downloading hiredis-3.0.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (165 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m166.0/166.0 kB\u001b[0m \u001b[31m4.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading redis-5.2.0-py3-none-any.whl (261 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m261.4/261.4 kB\u001b[0m \u001b[31m11.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: redis, hiredis, delayed\n",
            "Successfully installed delayed-1.2.0b2 hiredis-3.0.0 redis-5.2.0\n"
          ]
        }
      ],
      "source": [
        "# Install a pip package in the current Jupyter kernel\n",
        "import sys\n",
        "!{sys.executable} -m pip install imbalanced-learn delayed"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nA-scNoo7gY8"
      },
      "source": [
        "# Exercises\n",
        "\n",
        "## Exercise 1 - General Data Preprocessing (20 points)\n",
        "\n",
        "Our dataset needs cleaning before building any models. Some of the cleaning tasks are common in general, but depends on what kind of models we are building, sometimes we have to do additional processing. These additional tasks will be mentioned in each of the remaining two exercises later.\n",
        "\n",
        "Note that **we will be using this processed data from exercise 1 in each of the remaining two exercises**.\n",
        "\n",
        "For convenience, here are the attributes that we would treat them as **categorical attributes**: `day`, `quarter`, `department`, and `team`.\n",
        "\n",
        "Realize that `quarter` is not referring to certain months of the year, but certain days of the month. \"Quarter1\" represents days 1-7, \"Quarter2\" days 8-14, \"Quarter3\" days 15-21, \"Quarter4\" days 22-28, and \"Quarter5\" days 29-31\n",
        "\n",
        " - Drop the column `date`.\n",
        " - For each of the categorical attributes, **print out** all the unique elements.\n",
        " - For each of the categorical attributes, remap the duplicated items, if you find there are typos or spaces among the duplicated items.\n",
        "     - For example, \"a\" and \"a \" should be the same, so we need to update \"a \" to be \"a\".\n",
        "     - Another example, \"apple\" and \"appel\" should be the same, so you should update \"appel\" to be \"apple\".\n",
        "     \n",
        "\n",
        " - Create another column named `satisfied` that records the productivity performance. The behavior defined as follows. **This is the dependent variable we'd like to classify in this assignment.**\n",
        "     - Return True or 1 if `actual_productivity` is equal to or greater than `targeted_productivity`. Otherwise, return False or 0, which means the team fails to meet the expected performance.\n",
        " - Drop the columns `actual_productivity` and `targeted_productivity`.\n",
        "\n",
        "\n",
        " - Find and **print out** which columns/attributes that have empty vaules, e.g., NA, NaN, null, None.\n",
        " - You must use `df.describe()` or `df.info()` to display the data after preprocessing. **No credit** will be given if this step is omitted.\n",
        " - Fill the empty values with 0.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 87,
      "metadata": {
        "id": "hP-Qh9Nm7gY9",
        "outputId": "cf72d7bf-a784-4f87-e3c9-ba0736232fc0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 404
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['Thursday' 'Saturday' 'Sunday' 'Monday' 'Tuesday' 'Wednesday']\n",
            "['Quarter1' 'Quarter2' 'Quarter3' 'Quarter4' 'Quarter5']\n",
            "['sweing' 'finishing']\n",
            "[ 8  1 11 12  6  7  2  3  9 10  5  4]\n",
            "[ True False]\n",
            "wip\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "              team          smv           wip     over_time    incentive  \\\n",
              "count  1197.000000  1197.000000   1197.000000   1197.000000  1197.000000   \n",
              "mean      6.426901    15.062172    687.228070   4567.460317    38.210526   \n",
              "std       3.463963    10.943219   1514.582341   3348.823563   160.182643   \n",
              "min       1.000000     2.900000      0.000000      0.000000     0.000000   \n",
              "25%       3.000000     3.940000      0.000000   1440.000000     0.000000   \n",
              "50%       6.000000    15.260000    586.000000   3960.000000     0.000000   \n",
              "75%       9.000000    24.260000   1083.000000   6960.000000    50.000000   \n",
              "max      12.000000    54.560000  23122.000000  25920.000000  3600.000000   \n",
              "\n",
              "         idle_time     idle_men  no_of_style_change  no_of_workers  \n",
              "count  1197.000000  1197.000000         1197.000000    1197.000000  \n",
              "mean      0.730159     0.369256            0.150376      34.609858  \n",
              "std      12.709757     3.268987            0.427848      22.197687  \n",
              "min       0.000000     0.000000            0.000000       2.000000  \n",
              "25%       0.000000     0.000000            0.000000       9.000000  \n",
              "50%       0.000000     0.000000            0.000000      34.000000  \n",
              "75%       0.000000     0.000000            0.000000      57.000000  \n",
              "max     300.000000    45.000000            2.000000      89.000000  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-9fed4cce-49cd-43dd-a7df-dd16a0690d3c\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>team</th>\n",
              "      <th>smv</th>\n",
              "      <th>wip</th>\n",
              "      <th>over_time</th>\n",
              "      <th>incentive</th>\n",
              "      <th>idle_time</th>\n",
              "      <th>idle_men</th>\n",
              "      <th>no_of_style_change</th>\n",
              "      <th>no_of_workers</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>count</th>\n",
              "      <td>1197.000000</td>\n",
              "      <td>1197.000000</td>\n",
              "      <td>1197.000000</td>\n",
              "      <td>1197.000000</td>\n",
              "      <td>1197.000000</td>\n",
              "      <td>1197.000000</td>\n",
              "      <td>1197.000000</td>\n",
              "      <td>1197.000000</td>\n",
              "      <td>1197.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>mean</th>\n",
              "      <td>6.426901</td>\n",
              "      <td>15.062172</td>\n",
              "      <td>687.228070</td>\n",
              "      <td>4567.460317</td>\n",
              "      <td>38.210526</td>\n",
              "      <td>0.730159</td>\n",
              "      <td>0.369256</td>\n",
              "      <td>0.150376</td>\n",
              "      <td>34.609858</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>std</th>\n",
              "      <td>3.463963</td>\n",
              "      <td>10.943219</td>\n",
              "      <td>1514.582341</td>\n",
              "      <td>3348.823563</td>\n",
              "      <td>160.182643</td>\n",
              "      <td>12.709757</td>\n",
              "      <td>3.268987</td>\n",
              "      <td>0.427848</td>\n",
              "      <td>22.197687</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>min</th>\n",
              "      <td>1.000000</td>\n",
              "      <td>2.900000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>2.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25%</th>\n",
              "      <td>3.000000</td>\n",
              "      <td>3.940000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1440.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>9.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>50%</th>\n",
              "      <td>6.000000</td>\n",
              "      <td>15.260000</td>\n",
              "      <td>586.000000</td>\n",
              "      <td>3960.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>34.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>75%</th>\n",
              "      <td>9.000000</td>\n",
              "      <td>24.260000</td>\n",
              "      <td>1083.000000</td>\n",
              "      <td>6960.000000</td>\n",
              "      <td>50.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>57.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>max</th>\n",
              "      <td>12.000000</td>\n",
              "      <td>54.560000</td>\n",
              "      <td>23122.000000</td>\n",
              "      <td>25920.000000</td>\n",
              "      <td>3600.000000</td>\n",
              "      <td>300.000000</td>\n",
              "      <td>45.000000</td>\n",
              "      <td>2.000000</td>\n",
              "      <td>89.000000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-9fed4cce-49cd-43dd-a7df-dd16a0690d3c')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-9fed4cce-49cd-43dd-a7df-dd16a0690d3c button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-9fed4cce-49cd-43dd-a7df-dd16a0690d3c');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-d7dd254c-651f-441a-b0b5-a03e6845f77c\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-d7dd254c-651f-441a-b0b5-a03e6845f77c')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-d7dd254c-651f-441a-b0b5-a03e6845f77c button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "summary": "{\n  \"name\": \"#df\",\n  \"rows\": 8,\n  \"fields\": [\n    {\n      \"column\": \"team\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 421.1525987837647,\n        \"min\": 1.0,\n        \"max\": 1197.0,\n        \"num_unique_values\": 8,\n        \"samples\": [\n          6.426900584795321,\n          6.0,\n          1197.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"smv\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 417.1126021762678,\n        \"min\": 2.9,\n        \"max\": 1197.0,\n        \"num_unique_values\": 8,\n        \"samples\": [\n          15.062172096908938,\n          15.26,\n          1197.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"wip\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 7937.335318542234,\n        \"min\": 0.0,\n        \"max\": 23122.0,\n        \"num_unique_values\": 7,\n        \"samples\": [\n          1197.0,\n          687.2280701754386,\n          1083.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"over_time\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 8373.31562922651,\n        \"min\": 0.0,\n        \"max\": 25920.0,\n        \"num_unique_values\": 8,\n        \"samples\": [\n          4567.460317460317,\n          3960.0,\n          1197.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"incentive\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 1267.191974096936,\n        \"min\": 0.0,\n        \"max\": 3600.0,\n        \"num_unique_values\": 6,\n        \"samples\": [\n          1197.0,\n          38.21052631578947,\n          3600.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"idle_time\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 420.5086170079323,\n        \"min\": 0.0,\n        \"max\": 1197.0,\n        \"num_unique_values\": 5,\n        \"samples\": [\n          0.7301587301587301,\n          300.0,\n          12.709756518546547\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"idle_men\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 421.0349482146399,\n        \"min\": 0.0,\n        \"max\": 1197.0,\n        \"num_unique_values\": 5,\n        \"samples\": [\n          0.3692564745196324,\n          45.0,\n          3.26898732417817\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"no_of_style_change\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 423.07373830286184,\n        \"min\": 0.0,\n        \"max\": 1197.0,\n        \"num_unique_values\": 5,\n        \"samples\": [\n          0.15037593984962405,\n          2.0,\n          0.4278478565061976\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"no_of_workers\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 411.6130246489885,\n        \"min\": 2.0,\n        \"max\": 1197.0,\n        \"num_unique_values\": 8,\n        \"samples\": [\n          34.60985797827903,\n          34.0,\n          1197.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 87
        }
      ],
      "source": [
        "import pandas as pd\n",
        "# If put the data(.csv) under the same folder, you could use\n",
        "df = pd.read_csv('./garments_worker_productivity.csv')\n",
        "df = df.drop(columns=['date'])\n",
        "df.replace('finishing ', 'finishing',inplace=True)\n",
        "def satisfied(row):\n",
        "    return row['actual_productivity'] >= row['targeted_productivity']\n",
        "\n",
        "df['satisfied'] = df.apply(satisfied, axis=1)\n",
        "df = df.drop(columns=['actual_productivity','targeted_productivity'])\n",
        "print(df['day'].unique())\n",
        "print(df['quarter'].unique())\n",
        "print(df['department'].unique())\n",
        "print(df['team'].unique())\n",
        "print(df['satisfied'].unique())\n",
        "\n",
        "for col in df.items():\n",
        "    if col[1].isnull().any():\n",
        "        print(col[0])\n",
        "        df = df.fillna(0)\n",
        "\n",
        "df.describe()\n",
        "#df.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "o_Ui1K1a7gY-"
      },
      "source": [
        "## Exercise 2 - Naïve Bayes Classifier (40 points in total)\n",
        "\n",
        "### Exercise 2.1 - Additional Data Preprocessing (10 points)\n",
        "\n",
        "To build a Naïve Bayes Classifier, we need to further encode our categorical variables.\n",
        "\n",
        " - For each of the **categorical attributes**, encode the set of categories to be **0 ~ (n_classes - 1)**.\n",
        "     - For example, \\[\"paris\", \"paris\", \"tokyo\", \"amsterdam\"\\] should be encoded as \\[1, 1, 2, 0\\].\n",
        "     - Note that the order does not really matter, i.e., \\[0, 0, 1, 2\\] also works. But you have to start with 0 in your encodings.\n",
        "     - You can find information about this encoding in the discussion materials.\n",
        "\n",
        "\n",
        " - Split the data into training and testing set with the ratio of 80:20.\n",
        " - You **must** show the first five row of your encoded dataset, as well as the shape of your train test split. **No credit** will be given if this step is omitted."
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "TmX6sm1yGQhj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "\n",
        "myle = LabelEncoder()\n",
        "df_le = df.copy()\n",
        "df_le['day'] = myle.fit_transform(df['day'])\n",
        "df_le['quarter'] = myle.fit_transform(df['quarter'])\n",
        "df_le['department'] = myle.fit_transform(df['department'])\n",
        "df_le['team'] = myle.fit_transform(df['team'])\n",
        "df_le['satisfied'] = myle.fit_transform(df['satisfied'])\n",
        "\n",
        "df_cat = df_le.drop(['no_of_workers','no_of_style_change','smv','wip','over_time','incentive','idle_time','idle_men'], axis=1)\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(df_cat.drop(['satisfied'], axis=1), df_cat.satisfied, test_size=0.2, random_state=21)\n",
        "\n",
        "df_cat.head(), X_train.shape, X_test.shape\n"
      ],
      "metadata": {
        "id": "r9yoGwxbGC6A",
        "outputId": "816d6e42-d4aa-469c-b9fe-960029a0dc14",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 88,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(   quarter  department  day  team  satisfied\n",
              " 0        0           1    3     7          1\n",
              " 1        0           0    3     0          1\n",
              " 2        0           1    3    10          1\n",
              " 3        0           1    3    11          1\n",
              " 4        0           1    3     5          1,\n",
              " (957, 4),\n",
              " (240, 4))"
            ]
          },
          "metadata": {},
          "execution_count": 88
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n"
      ],
      "metadata": {
        "id": "U2BkcpHHE96I"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qe1K53wf7gY_"
      },
      "outputs": [],
      "source": [
        "# Remember to continue the task with your processed data from Exercise 1"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BIKtljxJ7gZA"
      },
      "source": [
        "### Exercise 2.2 - Naïve Bayes Classifier for Categorical Attributes (15 points)\n",
        "\n",
        "Use the categorical attributes **only**, please build a Categorical Naïve Bayes classifier that predicts the column `satisfied`. <br >\n",
        "Report the **testing result** using `classification_report`."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from sklearn.metrics import classification_report\n",
        "from sklearn.naive_bayes import CategoricalNB\n",
        "\n",
        "model = CategoricalNB()\n",
        "model.fit(X_train, y_train)\n",
        "y_pred = model.predict(X_test)\n",
        "print(classification_report(y_test, y_pred))\n",
        "\n",
        "# Remember to do this task with your processed data from Exercise 2.1\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "R5kEqm1gqcbg",
        "outputId": "4ce66ce1-a18a-46e2-efed-d1bc0a83f52b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.66      0.28      0.39        68\n",
            "           1       0.77      0.94      0.85       172\n",
            "\n",
            "    accuracy                           0.75       240\n",
            "   macro avg       0.71      0.61      0.62       240\n",
            "weighted avg       0.74      0.75      0.72       240\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "GlQMcaXAqbr3"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "T4rN1jOx7gZB"
      },
      "outputs": [],
      "source": [
        "# Remember to do this task with your processed data from Exercise 2.1"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n"
      ],
      "metadata": {
        "id": "ajKuVMxLM2fD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QuiO1EfG7gZC"
      },
      "source": [
        "### Exercise 2.3 - Naïve Bayes Classifier for Numerical Attributes (15 points)\n",
        "\n",
        "Use the numerical attributes **only**, please build a Gaussian Naïve Bayes classifier that predicts the column `satisfied`. <br >\n",
        "Report the **testing result** using `classification_report`.\n",
        "\n",
        "**Remember to scale your data. The scaling method is up to you.**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 89,
      "metadata": {
        "id": "lNDZ0LGO7gZE",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2ff6204b-3183-416e-ee55-91c39009d31f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "       False       1.00      0.04      0.08        68\n",
            "        True       0.73      1.00      0.84       172\n",
            "\n",
            "    accuracy                           0.73       240\n",
            "   macro avg       0.86      0.52      0.46       240\n",
            "weighted avg       0.80      0.73      0.63       240\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# Remember to do this task with your processed data from Exercise 2.1\n",
        "\n",
        "import numpy as np\n",
        "from sklearn.metrics import classification_report\n",
        "from sklearn.naive_bayes import GaussianNB\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "df_num = df.drop(['day','quarter','department','team'], axis=1)\n",
        "X_train, X_test, y_train, y_test = train_test_split(df_num.drop(['satisfied'], axis=1), df_num.satisfied, test_size=0.2, random_state=21)\n",
        "scaler = StandardScaler()\n",
        "X_train = scaler.fit_transform(X_train)\n",
        "X_test = scaler.transform(X_test)\n",
        "model = GaussianNB()\n",
        "model.fit(X_train, y_train)\n",
        "y_pred = model.predict(X_test)\n",
        "print(classification_report(y_test, y_pred))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RRExMRlx7gZF"
      },
      "source": [
        "## Exercies 3 - SVM Classifier (35 points in total)\n",
        "\n",
        "### Exercise 3.1 - Additional Data Preprocessing (10 points)\n",
        "\n",
        "To build a SVM Classifier, we need a different encoding for our categorical variables.\n",
        "\n",
        " - For each of the **categorical attributes**, encode them with **one-hot encoding**.\n",
        "     - You can find information about this encoding in the discussion materials.\n",
        "\n",
        "\n",
        " - Split the data into training and testing set with the ratio of 80:20.\n",
        " - You **must** show the first five row of your encoded dataset, as well as the shape of your train test split. **No credit** will be given if this step is omitted."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 91,
      "metadata": {
        "id": "yPhLqrlA7gZF",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1f161ee8-d9a5-4282-adf4-9354a80aebca"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(   quarter  department  day  team  satisfied\n",
              " 0        0           1    3     7          1\n",
              " 1        0           0    3     0          1\n",
              " 2        0           1    3    10          1\n",
              " 3        0           1    3    11          1\n",
              " 4        0           1    3     5          1,\n",
              " (957, 9),\n",
              " (240, 9))"
            ]
          },
          "metadata": {},
          "execution_count": 91
        }
      ],
      "source": [
        "# Remember to continue the task with your processed data from Exercise 1\n",
        "#from sklearn.preprocessing import OneHotEncoder\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "\n",
        "\n",
        "scaler = MinMaxScaler()\n",
        "categorical_columns = df.select_dtypes(include=['object']).columns.tolist()\n",
        "numerical_columns = df.select_dtypes(include=['int64', 'float64']).columns.tolist()\n",
        "df_num = df.drop(['day','quarter','department','team'], axis=1)\n",
        "df_cop = df.copy()\n",
        "df_cop = pd.get_dummies(df_cop, columns = categorical_columns)\n",
        "X_train, X_test, y_train, y_test = train_test_split(df.drop(['satisfied'], axis=1), df.satisfied, test_size=0.2, random_state=21)\n",
        "\n",
        "scaler.fit(X_train[numerical_columns])\n",
        "X_train = scaler.transform(X_train[numerical_columns])\n",
        "scaler.fit(X_test[numerical_columns])\n",
        "X_test = scaler.transform(X_test[numerical_columns])\n",
        "#X_train = pd.get_dummies(X_train, columns = categorical_columns)\n",
        "#X_test = pd.get_dummies(X_test, columns = categorical_columns)\n",
        "\n",
        "df_cat.head(), X_train.shape, X_test.shape\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "43zeNOoa7gZG"
      },
      "source": [
        "### Exercise 3.2 - SVM with Different Kernels (15 points)\n",
        "\n",
        "Using all the attributes we have, please build a SVM that predicts the column `satisfied`. <br >\n",
        "Specifically, please\n",
        " - Build one SVM with **linear kernel**.\n",
        " - Build another SVM but with **rbf kernel**.\n",
        " - Report the **testing results** of **both models** using `classification report`.\n",
        "\n",
        "The kernel is the only setting requirement. <br >\n",
        "Other hyperparameter tuning is not required. But make sure they are the same in these two SVMs if you'd like to tune the model. In other words, the only difference between the two SVMs should be the kernel setting.\n",
        "\n",
        "**Remember to scale your data. The scaling method is up to you.**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 81,
      "metadata": {
        "id": "edl1zzWg7gZG",
        "outputId": "7ae5310f-d38d-4127-ca3b-e55090d35794",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "       False       1.00      0.04      0.08        68\n",
            "        True       0.73      1.00      0.84       172\n",
            "\n",
            "    accuracy                           0.73       240\n",
            "   macro avg       0.86      0.52      0.46       240\n",
            "weighted avg       0.80      0.73      0.63       240\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "       False       1.00      0.03      0.06        68\n",
            "        True       0.72      1.00      0.84       172\n",
            "\n",
            "    accuracy                           0.72       240\n",
            "   macro avg       0.86      0.51      0.45       240\n",
            "weighted avg       0.80      0.72      0.62       240\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# Remember to do this task with your processed data from Exercise 3.1\n",
        "\n",
        "import numpy as np\n",
        "from sklearn.metrics import classification_report\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "#scaler = StandardScaler()\n",
        "model = SVC(kernel='linear')\n",
        "model.fit(X_train, y_train)\n",
        "y_pred = model.predict(X_test)\n",
        "print(classification_report(y_test, y_pred))\n",
        "\n",
        "model = SVC(kernel='rbf')\n",
        "model.fit(X_train, y_train)\n",
        "y_pred = model.predict(X_test)\n",
        "print(classification_report(y_test, y_pred))\n",
        "\n",
        "# Note: MinMax scaling was done in previous exercise"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x34A1Gol7gZG"
      },
      "source": [
        "### Exercise 3.3 - SVM with Over-sampling (10 points)\n",
        " - For the column `satisfied` in our **training set**, please **print out** the frequency of each class.\n",
        " - Oversample the **training data**.\n",
        " - For the column `satisfied` in the oversampled data, **print out** the frequency of each class  again.\n",
        " - Re-build the 2 SVMs with the same setting you have in Exercise 3.2, but **use oversampled training data** instead.\n",
        "     - Do not forget to scale the data first. As always, the scaling method is up to you.\n",
        " - Report the **testing result** with `classification_report`.\n",
        "\n",
        "You can use ANY methods listed on [here](https://imbalanced-learn.org/stable/references/over_sampling.html#) such as RandomOverSampler or SMOTE. <br >\n",
        "You are definitely welcomed to build your own oversampler. <br >\n",
        "\n",
        "Note that you do not have to over-sample your testing data."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kLsd3FCZ7gZG"
      },
      "outputs": [],
      "source": [
        "# Remember to do this task with your processed data from Exercise 3.1"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import imblearn.over_sampling\n",
        "from imblearn.over_sampling import RandomOverSampler\n",
        "import numpy as np\n",
        "from sklearn.metrics import classification_report\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "scaler = MinMaxScaler()\n",
        "print(y_train.value_counts())\n",
        "ros = RandomOverSampler(random_state=21)\n",
        "X_train_resampled, y_train_resampled = ros.fit_resample(X_train, y_train)\n",
        "scaler.fit(X_train_resampled)\n",
        "X_train_resampled = scaler.transform(X_train_resampled)\n",
        "print(y_train_resampled.value_counts())\n",
        "\n",
        "model_lin = SVC(kernel='linear')\n",
        "model_lin.fit(X_train_resampled, y_train_resampled)\n",
        "y_pred = model_lin.predict(X_test)\n",
        "print(classification_report(y_test, y_pred))\n",
        "\n",
        "model_rbf = SVC(kernel='rbf')\n",
        "model_rbf.fit(X_train_resampled, y_train_resampled)\n",
        "y_pred = model_rbf.predict(X_test)\n",
        "print(classification_report(y_test, y_pred))\n"
      ],
      "metadata": {
        "id": "2otestsvd-od",
        "outputId": "6482f64f-80ec-4f85-bafd-ff5717b8e988",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 83,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "satisfied\n",
            "True     703\n",
            "False    254\n",
            "Name: count, dtype: int64\n",
            "satisfied\n",
            "True     703\n",
            "False    703\n",
            "Name: count, dtype: int64\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "       False       0.47      0.68      0.55        68\n",
            "        True       0.85      0.70      0.76       172\n",
            "\n",
            "    accuracy                           0.69       240\n",
            "   macro avg       0.66      0.69      0.66       240\n",
            "weighted avg       0.74      0.69      0.70       240\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "       False       0.50      0.79      0.61        68\n",
            "        True       0.89      0.68      0.77       172\n",
            "\n",
            "    accuracy                           0.71       240\n",
            "   macro avg       0.69      0.74      0.69       240\n",
            "weighted avg       0.78      0.71      0.73       240\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NghAaQwm7o6S"
      },
      "source": [
        "## 4) Collaborative Statement (5 points)\n",
        "#### You must fill this out even if you worked alone to get credit.\n",
        "\n",
        "It is mandatory to include a Statement of Collaboration in each submission, that follows the guidelines below.\n",
        "Include the names of everyone involved in the discussions (especially in-person ones), and what was discussed.\n",
        "All students are required to follow the academic honesty guidelines posted on the course website. For\n",
        "programming assignments in particular, I encourage students to organize (perhaps using Piazza) to discuss the\n",
        "task descriptions, requirements, possible bugs in the support code, and the relevant technical content before they\n",
        "start working on it. However, you should not discuss the specific solutions, and as a guiding principle, you are\n",
        "not allowed to take anything written or drawn away from these discussions (no photographs of the blackboard,\n",
        "written notes, referring to Piazza, etc.). Especially after you have started working on the assignment, try to restrict\n",
        "the discussion to Piazza as much as possible, so that there is no doubt as to the extent of your collaboration.\n",
        "\n",
        "Even if you did not use any outside resources or collaborate with anyone, please state that explicitly in the space below."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zAGHaltx7usH"
      },
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.10"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}